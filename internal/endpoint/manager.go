package endpoint

import (
	"context"
	"fmt"
	"log/slog"
	"net/http"
	"sort"
	"sync"
	"time"

	"cc-forwarder/config"
	"cc-forwarder/internal/events"
	"cc-forwarder/internal/transport"
	"cc-forwarder/internal/utils"
)

// EndpointStatus represents the health status of an endpoint
type EndpointStatus struct {
	Healthy         bool
	LastCheck       time.Time
	ResponseTime    time.Duration
	ConsecutiveFails int
	NeverChecked    bool  // è¡¨ç¤ºä»æœªè¢«æ£€æµ‹è¿‡
}

// Endpoint represents an endpoint with its configuration and status
type Endpoint struct {
	Config config.EndpointConfig
	Status EndpointStatus
	mutex  sync.RWMutex
}

// Manager manages endpoints and their health status
type Manager struct {
	endpoints    []*Endpoint
	endpointsMu  sync.RWMutex  // v5.0+: ä¿æŠ¤ endpoints åˆ‡ç‰‡çš„å¹¶å‘è®¿é—®
	config       *config.Config
	client       *http.Client
	ctx          context.Context
	cancel       context.CancelFunc
	wg           sync.WaitGroup
	fastTester   *FastTester
	groupManager *GroupManager
	keyManager   *KeyManager // ç®¡ç†å¤š API Key çŠ¶æ€
	// EventBus for decoupled event publishing
	eventBus     events.EventBus
	// å¥åº·æ£€æŸ¥å®Œæˆå›è°ƒï¼ˆç”¨äºæ¨é€ Wails äº‹ä»¶ï¼‰
	onHealthCheckComplete func()
}


// NewManager creates a new endpoint manager
func NewManager(cfg *config.Config) *Manager {
	ctx, cancel := context.WithCancel(context.Background())
	
	// Create transport with proxy support
	httpTransport, err := transport.CreateTransport(cfg)
	if err != nil {
		slog.Error(fmt.Sprintf("âŒ Failed to create HTTP transport with proxy: %s", err.Error()))
		// Fall back to default transport
		httpTransport = &http.Transport{}
	}
	
	
	manager := &Manager{
		config:       cfg,
		client: &http.Client{
			Timeout:   cfg.Health.Timeout,
			Transport: httpTransport,
		},
		ctx:          ctx,
		cancel:       cancel,
		fastTester:   NewFastTester(cfg),
		groupManager: NewGroupManager(cfg),
		keyManager:   NewKeyManager(), // åˆå§‹åŒ– Key ç®¡ç†å™¨
	}

	// Initialize endpoints
	for _, endpointCfg := range cfg.Endpoints {
		endpoint := &Endpoint{
			Config: endpointCfg,
			Status: EndpointStatus{
				Healthy:      false, // Start pessimistic, let health checks determine actual status
				LastCheck:    time.Now(),
				NeverChecked: true,  // æ ‡è®°ä¸ºæœªæ£€æµ‹
			},
		}
		manager.endpoints = append(manager.endpoints, endpoint)

		// åˆå§‹åŒ–ç«¯ç‚¹çš„ Key çŠ¶æ€
		tokenCount := len(endpointCfg.Tokens)
		if tokenCount == 0 && endpointCfg.Token != "" {
			tokenCount = 1 // å• Token ç®—ä½œ 1 ä¸ª
		}
		apiKeyCount := len(endpointCfg.ApiKeys)
		if apiKeyCount == 0 && endpointCfg.ApiKey != "" {
			apiKeyCount = 1 // å• API Key ç®—ä½œ 1 ä¸ª
		}
		manager.keyManager.InitEndpoint(endpointCfg.Name, tokenCount, apiKeyCount)
	}

	// Set manager reference in fast tester for dynamic token resolution
	manager.fastTester.SetManager(manager)

	// Initialize groups from endpoints
	manager.groupManager.UpdateGroups(manager.endpoints)

	return manager
}

// Start starts the health checking routine
func (m *Manager) Start() {
	m.wg.Add(1)
	go m.healthCheckLoop()
}

// Stop stops the health checking routine
func (m *Manager) Stop() {
	m.cancel()
	m.wg.Wait()
}

// UpdateConfig updates the manager configuration (hot-reload)
// v5.0 Desktop: åªæ›´æ–°é…ç½®å‚æ•°ï¼Œä¸é‡å»ºç«¯ç‚¹ï¼ˆç«¯ç‚¹å®Œå…¨ç”±æ•°æ®åº“ç®¡ç†ï¼‰
func (m *Manager) UpdateConfig(cfg *config.Config) {
	m.config = cfg

	// åªæ›´æ–° GroupManager é…ç½®
	m.groupManager.UpdateConfig(cfg)
	slog.Debug("ğŸ”„ [çƒ­æ›´æ–°] æ›´æ–°é…ç½®å‚æ•°å®Œæˆï¼Œç«¯ç‚¹ä¿æŒä¸å˜")
	
	// Update fast tester with new config
	if m.fastTester != nil {
		m.fastTester.UpdateConfig(cfg)
	}
	
	// Recreate transport with new proxy configuration
	if transport, err := transport.CreateTransport(cfg); err == nil {
		m.client = &http.Client{
			Transport: transport,
			Timeout:   cfg.Health.Timeout,
		}
	}
}

// GetHealthyEndpoints returns a list of healthy endpoints from active groups based on strategy
func (m *Manager) GetHealthyEndpoints() []*Endpoint {
	// v5.0+: ä½¿ç”¨å¿«ç…§æœºåˆ¶
	m.endpointsMu.RLock()
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)
	m.endpointsMu.RUnlock()

	// First filter by active groups
	// v5.0: SQLite æ¨¡å¼ä¸‹ï¼Œenabled=true â‡” group.IsActive=trueï¼ˆå·²åŒæ­¥ï¼‰
	activeEndpoints := m.groupManager.FilterEndpointsByActiveGroups(snapshot)

	// Then filter by health status
	var healthy []*Endpoint
	for _, endpoint := range activeEndpoints {
		endpoint.mutex.RLock()
		if endpoint.Status.Healthy {
			healthy = append(healthy, endpoint)
		}
		endpoint.mutex.RUnlock()
	}

	return m.sortHealthyEndpoints(healthy, true) // Show logs by default
}

// sortHealthyEndpoints sorts healthy endpoints based on strategy with optional logging
func (m *Manager) sortHealthyEndpoints(healthy []*Endpoint, showLogs bool) []*Endpoint {
	// Sort based on strategy
	switch m.config.Strategy.Type {
	case "priority":
		sort.Slice(healthy, func(i, j int) bool {
			return healthy[i].Config.Priority < healthy[j].Config.Priority
		})
	case "fastest":
		// Log endpoint latencies for fastest strategy (only if showLogs is true)
		if len(healthy) > 1 && showLogs {
			slog.Info("ğŸ“Š [Fastest Strategy] åŸºäºå¥åº·æ£€æŸ¥çš„ç«¯ç‚¹å»¶è¿Ÿæ’åº:")
			for _, ep := range healthy {
				ep.mutex.RLock()
				responseTime := ep.Status.ResponseTime
				ep.mutex.RUnlock()
				slog.Info(fmt.Sprintf("  â±ï¸ %s - å»¶è¿Ÿ: %dms (æ¥æº: å®šæœŸå¥åº·æ£€æŸ¥)", 
					ep.Config.Name, responseTime.Milliseconds()))
			}
		}
		
		sort.Slice(healthy, func(i, j int) bool {
			healthy[i].mutex.RLock()
			healthy[j].mutex.RLock()
			defer healthy[i].mutex.RUnlock()
			defer healthy[j].mutex.RUnlock()
			return healthy[i].Status.ResponseTime < healthy[j].Status.ResponseTime
		})
	}

	return healthy
}

// GetFastestEndpointsWithRealTimeTest returns endpoints from active groups sorted by real-time testing
func (m *Manager) GetFastestEndpointsWithRealTimeTest(ctx context.Context) []*Endpoint {
	// v5.0+: ä½¿ç”¨å¿«ç…§æœºåˆ¶
	m.endpointsMu.RLock()
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)
	m.endpointsMu.RUnlock()

	// First get endpoints from active groups and filter by health
	activeEndpoints := m.groupManager.FilterEndpointsByActiveGroups(snapshot)
	
	var healthy []*Endpoint
	for _, endpoint := range activeEndpoints {
		endpoint.mutex.RLock()
		if endpoint.Status.Healthy {
			healthy = append(healthy, endpoint)
		}
		endpoint.mutex.RUnlock()
	}
	
	if len(healthy) == 0 {
		return healthy
	}

	// If not using fastest strategy or fast test disabled, apply sorting with logging
	if m.config.Strategy.Type != "fastest" || !m.config.Strategy.FastTestEnabled {
		return m.sortHealthyEndpoints(healthy, true) // Show logs
	}

	// Check if we have cached fast test results first
	testResults, usedCache := m.fastTester.TestEndpointsParallel(ctx, healthy)
	
	// Only show health check sorting if we're NOT using cache
	if !usedCache && m.config.Strategy.Type == "fastest" && len(healthy) > 1 {
		slog.InfoContext(ctx, "ğŸ“Š [Fastest Strategy] åŸºäºå¥åº·æ£€æŸ¥çš„æ´»è·ƒç»„ç«¯ç‚¹å»¶è¿Ÿæ’åº:")
		for _, ep := range healthy {
			ep.mutex.RLock()
			responseTime := ep.Status.ResponseTime
			group := ep.Config.Group
			ep.mutex.RUnlock()
			slog.InfoContext(ctx, fmt.Sprintf("  â±ï¸ %s (ç»„: %s) - å»¶è¿Ÿ: %dms (æ¥æº: å®šæœŸå¥åº·æ£€æŸ¥)", 
				ep.Config.Name, group, responseTime.Milliseconds()))
		}
	}
	
	// Log ALL test results first (including failures) - but only if cache wasn't used
	if len(testResults) > 0 && !usedCache {
		slog.InfoContext(ctx, "ğŸ” [Fastest Response Mode] æ´»è·ƒç»„ç«¯ç‚¹æ€§èƒ½æµ‹è¯•ç»“æœ:")
		successCount := 0
		for _, result := range testResults {
			group := result.Endpoint.Config.Group
			if result.Success {
				successCount++
				slog.InfoContext(ctx, fmt.Sprintf("  âœ… å¥åº· %s (ç»„: %s) - å“åº”æ—¶é—´: %dms", 
					result.Endpoint.Config.Name, group,
					result.ResponseTime.Milliseconds()))
			} else {
				errorMsg := ""
				if result.Error != nil {
					errorMsg = fmt.Sprintf(" - é”™è¯¯: %s", result.Error.Error())
				}
				slog.InfoContext(ctx, fmt.Sprintf("  âŒ å¼‚å¸¸ %s (ç»„: %s) - å“åº”æ—¶é—´: %dms%s", 
					result.Endpoint.Config.Name, group,
					result.ResponseTime.Milliseconds(),
					errorMsg))
			}
		}
		
		slog.InfoContext(ctx, fmt.Sprintf("ğŸ“Š [æµ‹è¯•æ‘˜è¦] æ´»è·ƒç»„æµ‹è¯•: %dä¸ªç«¯ç‚¹, å¥åº·: %dä¸ª, å¼‚å¸¸: %dä¸ª",
			len(testResults), successCount, len(testResults)-successCount))
	}
	
	// Sort by response time (only successful results)
	sortedResults := SortByResponseTime(testResults)
	
	if len(sortedResults) == 0 {
		slog.WarnContext(ctx, "âš ï¸ [Fastest Response Mode] æ´»è·ƒç»„æ‰€æœ‰ç«¯ç‚¹æµ‹è¯•å¤±è´¥ï¼Œå›é€€åˆ°å¥åº·æ£€æŸ¥æ¨¡å¼")
		return healthy // Fall back to health check results if no fast tests succeeded
	}
	
	// Convert back to endpoint slice
	endpoints := make([]*Endpoint, 0, len(sortedResults))
	for _, result := range sortedResults {
		endpoints = append(endpoints, result.Endpoint)
	}

	// Log the successful endpoint ranking
	if len(endpoints) > 0 {
		// Show the fastest endpoint selection
		fastestEndpoint := endpoints[0]
		var fastestTime int64
		for _, result := range sortedResults {
			if result.Endpoint == fastestEndpoint {
				fastestTime = result.ResponseTime.Milliseconds()
				break
			}
		}
		
		cacheIndicator := ""
		if usedCache {
			cacheIndicator = " (ç¼“å­˜)"
		}
		
		slog.InfoContext(ctx, fmt.Sprintf("ğŸš€ [Fastest Response Mode] é€‰æ‹©æœ€å¿«ç«¯ç‚¹: %s - %dms%s", 
			fastestEndpoint.Config.Name, fastestTime, cacheIndicator))
		
		// Show other available endpoints if there are more than one
		if len(endpoints) > 1 && !usedCache {
			slog.InfoContext(ctx, "ğŸ“‹ [å¤‡ç”¨ç«¯ç‚¹] å…¶ä»–å¯ç”¨ç«¯ç‚¹:")
			for i := 1; i < len(endpoints); i++ {
				ep := endpoints[i]
				var responseTime int64
				var epGroup string
				for _, result := range sortedResults {
					if result.Endpoint == ep {
						responseTime = result.ResponseTime.Milliseconds()
						epGroup = result.Endpoint.Config.Group
						break
					}
				}
				slog.InfoContext(ctx, fmt.Sprintf("  ğŸ”„ å¤‡ç”¨ %s (ç»„: %s) - å“åº”æ—¶é—´: %dms", 
					ep.Config.Name, epGroup, responseTime))
			}
		}
	}

	return endpoints
}

// GetEndpointByName returns an endpoint by name, only from active groups
func (m *Manager) GetEndpointByName(name string) *Endpoint {
	// v5.0+: ä½¿ç”¨å¿«ç…§æœºåˆ¶
	m.endpointsMu.RLock()
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)
	m.endpointsMu.RUnlock()

	// First filter by active groups
	activeEndpoints := m.groupManager.FilterEndpointsByActiveGroups(snapshot)

	// Then find by name
	for _, endpoint := range activeEndpoints {
		if endpoint.Config.Name == name {
			return endpoint
		}
	}
	return nil
}

// GetEndpointByNameAny returns an endpoint by name from all endpoints (ignoring group status)
func (m *Manager) GetEndpointByNameAny(name string) *Endpoint {
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()

	for _, endpoint := range m.endpoints {
		if endpoint.Config.Name == name {
			return endpoint
		}
	}
	return nil
}

// GetAllEndpoints returns all endpoints (deprecated: use GetEndpoints instead)
func (m *Manager) GetAllEndpoints() []*Endpoint {
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()

	result := make([]*Endpoint, len(m.endpoints))
	copy(result, m.endpoints)
	return result
}

// GetTokenForEndpoint dynamically resolves the token for an endpoint
// If the endpoint has its own token, return it
// If not, find the first endpoint in the same group that has a token
// æ”¯æŒå¤š Token é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ tokens æ•°ç»„ä¸­å½“å‰æ¿€æ´»çš„ Token
func (m *Manager) GetTokenForEndpoint(ep *Endpoint) string {
	// 1. ä¼˜å…ˆä½¿ç”¨å¤š Tokens é…ç½®ï¼ˆç«¯ç‚¹ç‹¬ç«‹ç®¡ç†ï¼‰
	if len(ep.Config.Tokens) > 0 {
		activeIndex := m.keyManager.GetActiveTokenIndex(ep.Config.Name)
		if activeIndex >= 0 && activeIndex < len(ep.Config.Tokens) {
			return ep.Config.Tokens[activeIndex].Value
		}
		return ep.Config.Tokens[0].Value // å›é€€åˆ°ç¬¬ä¸€ä¸ª
	}

	// 2. ä½¿ç”¨å• Token é…ç½®
	if ep.Config.Token != "" {
		return ep.Config.Token
	}

	// 3. ç»„å†…ç»§æ‰¿ï¼ˆä»…å¯¹å• Token ä¿æŒåŸæœ‰è¡Œä¸ºï¼Œå¤š Token ä¸ç»§æ‰¿ï¼‰
	groupName := ep.Config.Group
	if groupName == "" {
		groupName = "Default"
	}

	// v5.0+: ä½¿ç”¨è¯»é”éå† endpoints
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()

	// Search through all endpoints for the same group
	for _, endpoint := range m.endpoints {
		endpointGroup := endpoint.Config.Group
		if endpointGroup == "" {
			endpointGroup = "Default"
		}

		// If same group and has token (only single token inheritance)
		if endpointGroup == groupName && endpoint.Config.Token != "" {
			return endpoint.Config.Token
		}
	}

	// 4. No token found in the group
	return ""
}

// GetApiKeyForEndpoint dynamically resolves the API key for an endpoint
// If the endpoint has its own api-key, return it
// If not, find the first endpoint in the same group that has an api-key
// æ”¯æŒå¤š API Key é…ç½®ï¼šä¼˜å…ˆä½¿ç”¨ api-keys æ•°ç»„ä¸­å½“å‰æ¿€æ´»çš„ API Key
func (m *Manager) GetApiKeyForEndpoint(ep *Endpoint) string {
	// 1. ä¼˜å…ˆä½¿ç”¨å¤š ApiKeys é…ç½®ï¼ˆç«¯ç‚¹ç‹¬ç«‹ç®¡ç†ï¼‰
	if len(ep.Config.ApiKeys) > 0 {
		activeIndex := m.keyManager.GetActiveApiKeyIndex(ep.Config.Name)
		if activeIndex >= 0 && activeIndex < len(ep.Config.ApiKeys) {
			return ep.Config.ApiKeys[activeIndex].Value
		}
		return ep.Config.ApiKeys[0].Value // å›é€€åˆ°ç¬¬ä¸€ä¸ª
	}

	// 2. ä½¿ç”¨å• ApiKey é…ç½®
	if ep.Config.ApiKey != "" {
		return ep.Config.ApiKey
	}

	// 3. ç»„å†…ç»§æ‰¿ï¼ˆä»…å¯¹å• ApiKey ä¿æŒåŸæœ‰è¡Œä¸ºï¼Œå¤š ApiKey ä¸ç»§æ‰¿ï¼‰
	groupName := ep.Config.Group
	if groupName == "" {
		groupName = "Default"
	}

	// v5.0+: ä½¿ç”¨è¯»é”éå† endpoints
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()

	// Search through all endpoints for the same group
	for _, endpoint := range m.endpoints {
		endpointGroup := endpoint.Config.Group
		if endpointGroup == "" {
			endpointGroup = "Default"
		}

		// If same group and has api-key (only single api-key inheritance)
		if endpointGroup == groupName && endpoint.Config.ApiKey != "" {
			return endpoint.Config.ApiKey
		}
	}

	// 4. No api-key found in the group
	return ""
}

// GetConfig returns the manager's configuration
func (m *Manager) GetConfig() *config.Config {
	return m.config
}

// GetGroupManager returns the group manager
func (m *Manager) GetGroupManager() *GroupManager {
	return m.groupManager
}


// SetEventBus è®¾ç½®EventBusäº‹ä»¶æ€»çº¿
func (m *Manager) SetEventBus(eventBus events.EventBus) {
	m.eventBus = eventBus
}

// SetOnHealthCheckComplete è®¾ç½®å¥åº·æ£€æŸ¥å®Œæˆå›è°ƒ
// ç”¨äº Wails æ¡Œé¢åº”ç”¨åœ¨å®šæ—¶å¥åº·æ£€æŸ¥å®Œæˆåæ¨é€äº‹ä»¶åˆ°å‰ç«¯
func (m *Manager) SetOnHealthCheckComplete(fn func()) {
	m.onHealthCheckComplete = fn
}

// notifyWebInterface é€šè¿‡EventBuså‘å¸ƒç«¯ç‚¹çŠ¶æ€å˜åŒ–äº‹ä»¶
func (m *Manager) notifyWebInterface(endpoint *Endpoint) {
	if m.eventBus == nil {
		return
	}
	
	endpoint.mutex.RLock()
	status := endpoint.Status
	endpoint.mutex.RUnlock()
	
	// ç¡®å®šäº‹ä»¶ç±»å‹å’Œä¼˜å…ˆçº§
	eventType := events.EventEndpointHealthy
	priority := events.PriorityHigh
	changeType := "status_changed"
	
	if !status.Healthy {
		eventType = events.EventEndpointUnhealthy
		priority = events.PriorityCritical
		changeType = "health_changed"
	}
	
	m.eventBus.Publish(events.Event{
		Type:     eventType,
		Source:   "endpoint_manager",
		Priority: priority,
		Data: map[string]interface{}{
			"endpoint":        endpoint.Config.Name,
			"healthy":         status.Healthy,
			"response_time":   utils.FormatResponseTime(status.ResponseTime),
			"last_check":      status.LastCheck.Format("2006-01-02 15:04:05"),
			"consecutive_fails": status.ConsecutiveFails,
			"change_type":     changeType,
		},
	})
}

// ManualActivateGroup manually activates a specific group via web interface
func (m *Manager) ManualActivateGroup(groupName string) error {
	err := m.groupManager.ManualActivateGroup(groupName)
	if err != nil {
		return err
	}

	// Notify web interface about group change
	go m.notifyWebGroupChange("group_manually_activated", groupName)

	return nil
}

// ManualActivateGroupWithForce manually activates a specific group via web interface with force option
func (m *Manager) ManualActivateGroupWithForce(groupName string, force bool) error {
	err := m.groupManager.ManualActivateGroupWithForce(groupName, force)
	if err != nil {
		return err
	}

	// Notify web interface about group change
	if force {
		go m.notifyWebGroupChange("group_force_activated", groupName)
	} else {
		go m.notifyWebGroupChange("group_manually_activated", groupName)
	}

	return nil
}

// ManualPauseGroup manually pauses a group via web interface
func (m *Manager) ManualPauseGroup(groupName string, duration time.Duration) error {
	err := m.groupManager.ManualPauseGroup(groupName, duration)
	if err != nil {
		return err
	}
	
	// Notify web interface about group change
	go m.notifyWebGroupChange("group_manually_paused", groupName)
	
	return nil
}

// ManualResumeGroup manually resumes a paused group via web interface
func (m *Manager) ManualResumeGroup(groupName string) error {
	err := m.groupManager.ManualResumeGroup(groupName)
	if err != nil {
		return err
	}
	
	// Notify web interface about group change
	go m.notifyWebGroupChange("group_manually_resumed", groupName)
	
	return nil
}

// GetGroupDetails returns detailed information about all groups for web interface
func (m *Manager) GetGroupDetails() map[string]interface{} {
	return m.groupManager.GetGroupDetails()
}

// notifyWebGroupChange notifies the web interface about group management changes
func (m *Manager) notifyWebGroupChange(eventType, groupName string) {
	// æ£€æŸ¥EventBusæ˜¯å¦å¯ç”¨
	if m.eventBus == nil {
		slog.Debug("[ç»„ç®¡ç†] EventBusæœªè®¾ç½®ï¼Œè·³è¿‡ç»„çŠ¶æ€å˜åŒ–é€šçŸ¥")
		return
	}

	// è·å–ç»„è¯¦ç»†ä¿¡æ¯
	groupDetails := m.GetGroupDetails()

	// æ„å»ºäº‹ä»¶æ•°æ®
	data := map[string]interface{}{
		"event":     eventType,
		"group":     groupName,
		"timestamp": time.Now().Format("2006-01-02 15:04:05"),
		"details":   groupDetails,
	}

	// ä½¿ç”¨EventBuså‘å¸ƒç»„çŠ¶æ€å˜åŒ–äº‹ä»¶
	m.eventBus.Publish(events.Event{
		Type:      events.EventGroupStatusChanged,
		Source:    "endpoint_manager",
		Timestamp: time.Now(),
		Priority:  events.PriorityHigh,
		Data:      data,
	})

	slog.Debug(fmt.Sprintf("ğŸ“¢ [ç»„ç®¡ç†] å‘å¸ƒç»„çŠ¶æ€å˜åŒ–äº‹ä»¶: %s (ç»„: %s)", eventType, groupName))
}

// notifyGroupHealthStats é€šçŸ¥ç»„å¥åº·ç»Ÿè®¡å˜åŒ–ï¼ˆv4.0: å·²å¼ƒç”¨ï¼Œå‰ç«¯ä¸å†ç›‘å¬ï¼‰
func (m *Manager) notifyGroupHealthStats(groupName string) {
	// v4.0: å‰ç«¯ä¸å†ç›‘å¬æ­¤äº‹ä»¶ï¼Œæ•´ä¸ªå‡½æ•°å·²ç¦ç”¨
	if m.eventBus == nil {
		return
	}

	// å¤„ç†ç©ºç»„åï¼Œé»˜è®¤ä¸º"Default"
	if groupName == "" {
		groupName = "Default"
	}

	// v4.0: å‰ç«¯ä¸å†ç›‘å¬ç»„å¥åº·ç»Ÿè®¡äº‹ä»¶ï¼Œæ³¨é‡Šæ‰ä»¥å‡å°‘æ— ç”¨å¼€é”€
	// è·å–ç»„è¯¦ç»†ä¿¡æ¯
	// groupDetails := m.groupManager.GetGroupDetails()
	// if groups, ok := groupDetails["groups"].([]map[string]interface{}); ok {
	// 	// æŸ¥æ‰¾ç›®æ ‡ç»„çš„å¥åº·ç»Ÿè®¡
	// 	for _, group := range groups {
	// 		if groupNameStr, exists := group["name"]; exists && groupNameStr == groupName {
	// 			// å‘å¸ƒç»„å¥åº·ç»Ÿè®¡å˜åŒ–äº‹ä»¶
	// 			m.eventBus.Publish(events.Event{
	// 				Type:     events.EventGroupHealthStatsChanged,
	// 				Source:   "endpoint_manager",
	// 				Priority: events.PriorityHigh,
	// 				Data: map[string]interface{}{
	// 					"group":               groupName,
	// 					"healthy_endpoints":   group["healthy_endpoints"],
	// 					"unhealthy_endpoints": group["unhealthy_endpoints"],
	// 					"total_endpoints":     group["total_endpoints"],
	// 					"is_active":           group["is_active"],
	// 					"status":              group["status"],
	// 					"change_type":         "health_stats_changed",
	// 					"timestamp":           time.Now().Format("2006-01-02 15:04:05"),
	// 				},
	// 			})
	//
	// 			slog.Debug(fmt.Sprintf("ğŸ“Š [ç»„å¥åº·ç»Ÿè®¡] æˆåŠŸå‘å¸ƒç»„å¥åº·ç»Ÿè®¡å˜åŒ–äº‹ä»¶: %s (å¥åº·: %v/%v)",
	// 				groupName, group["healthy_endpoints"], group["total_endpoints"]))
	// 			return
	// 		}
	// 	}
	// }

	// v4.0: ç»„å¥åº·ç»Ÿè®¡ä¸å†ä½¿ç”¨ï¼Œæœªæ‰¾åˆ°ä¹Ÿä¸è­¦å‘Š
}

// healthCheckLoop runs the health check routine
func (m *Manager) healthCheckLoop() {
	defer m.wg.Done()

	// è·å–å½“å‰æ£€æŸ¥é—´éš”
	getCheckInterval := func() time.Duration {
		interval := m.config.Health.CheckInterval
		if interval <= 0 {
			interval = 30 * time.Second // é»˜è®¤30ç§’æ£€æŸ¥ä¸€æ¬¡
		}
		return interval
	}

	currentInterval := getCheckInterval()
	ticker := time.NewTicker(currentInterval)
	defer ticker.Stop()

	// Initial health check
	m.performHealthChecks()

	for {
		select {
		case <-m.ctx.Done():
			return
		case <-ticker.C:
			m.performHealthChecks()

			// æ£€æŸ¥é…ç½®æ˜¯å¦å˜åŒ–ï¼ŒåŠ¨æ€è°ƒæ•´é—´éš”
			newInterval := getCheckInterval()
			if newInterval != currentInterval {
				slog.Info("ğŸ”„ [å¥åº·æ£€æŸ¥] é—´éš”å·²æ›´æ–°", "old", currentInterval, "new", newInterval)
				currentInterval = newInterval
				ticker.Reset(currentInterval)
			}
		}
	}
}

// performHealthChecks performs health checks on all endpoints
func (m *Manager) performHealthChecks() {
	// v5.0+: ä½¿ç”¨å¿«ç…§æœºåˆ¶ï¼Œä¸é˜»å¡åŠ¨æ€å¢åˆ æ“ä½œ
	m.endpointsMu.RLock()
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)
	m.endpointsMu.RUnlock()

	// v5.0: SQLite å­˜å‚¨æ¨¡å¼ä¸‹å§‹ç»ˆæ£€æŸ¥æ‰€æœ‰ç«¯ç‚¹ï¼ˆä¸ç®¡ enabled çŠ¶æ€ï¼‰
	// v4.0: YAML é…ç½®æ¨¡å¼ä¸‹æ ¹æ® auto/manual æ¨¡å¼å†³å®š
	var endpointsToCheck []*Endpoint

	// åˆ¤æ–­æ˜¯å¦ä¸º SQLite å­˜å‚¨æ¨¡å¼
	isSQLiteMode := m.config.EndpointsStorage.Type == "sqlite"

	if isSQLiteMode {
		// v5.0 SQLite æ¨¡å¼ï¼šæ£€æŸ¥æ‰€æœ‰ç«¯ç‚¹ï¼ˆåŒ…æ‹¬ enabled=false çš„ï¼‰
		endpointsToCheck = snapshot

		if len(endpointsToCheck) == 0 {
			slog.Debug("ğŸ©º [å¥åº·æ£€æŸ¥] æ²¡æœ‰é…ç½®çš„ç«¯ç‚¹ï¼Œè·³è¿‡å¥åº·æ£€æŸ¥")
			return
		}

		slog.Debug(fmt.Sprintf("ğŸ©º [å¥åº·æ£€æŸ¥] SQLite æ¨¡å¼ï¼šæ£€æŸ¥æ‰€æœ‰ %d ä¸ªç«¯ç‚¹ï¼ˆåŒ…æ‹¬æœªæ¿€æ´»ï¼‰",
			len(endpointsToCheck)))
	} else if m.config.Group.AutoSwitchBetweenGroups {
		// v4.0 Auto mode: only check active group endpoints
		endpointsToCheck = m.groupManager.FilterEndpointsByActiveGroups(snapshot)

		if len(endpointsToCheck) == 0 {
			slog.Debug("ğŸ©º [å¥åº·æ£€æŸ¥] è‡ªåŠ¨æ¨¡å¼ä¸‹æ²¡æœ‰æ´»è·ƒç»„ä¸­çš„ç«¯ç‚¹ï¼Œè·³è¿‡å¥åº·æ£€æŸ¥")
			return
		}

		slog.Debug(fmt.Sprintf("ğŸ©º [å¥åº·æ£€æŸ¥] è‡ªåŠ¨æ¨¡å¼ï¼šå¼€å§‹æ£€æŸ¥ %d ä¸ªæ´»è·ƒç»„ç«¯ç‚¹ (æ€»å…± %d ä¸ªç«¯ç‚¹)",
			len(endpointsToCheck), len(snapshot)))
	} else {
		// v4.0 Manual mode: check all endpoints to determine their health status
		endpointsToCheck = snapshot

		if len(endpointsToCheck) == 0 {
			slog.Debug("ğŸ©º [å¥åº·æ£€æŸ¥] æ²¡æœ‰é…ç½®çš„ç«¯ç‚¹ï¼Œè·³è¿‡å¥åº·æ£€æŸ¥")
			return
		}

		slog.Debug(fmt.Sprintf("ğŸ©º [å¥åº·æ£€æŸ¥] æ‰‹åŠ¨æ¨¡å¼ï¼šæ£€æŸ¥æ‰€æœ‰ %d ä¸ªç«¯ç‚¹çš„å¥åº·çŠ¶æ€",
			len(endpointsToCheck)))
	}
	
	var wg sync.WaitGroup
	
	// Check the determined endpoints based on mode
	for _, endpoint := range endpointsToCheck {
		wg.Add(1)
		go func(ep *Endpoint) {
			defer wg.Done()
			m.checkEndpointHealth(ep)
		}(endpoint)
	}
	
	wg.Wait()
	
	// Count healthy endpoints after checks
	healthyCount := 0
	for _, ep := range endpointsToCheck {
		if ep.IsHealthy() {
			healthyCount++
		}
	}
	
	if m.config.Group.AutoSwitchBetweenGroups {
		slog.Debug(fmt.Sprintf("ğŸ©º [å¥åº·æ£€æŸ¥] å®Œæˆæ£€æŸ¥ - æ´»è·ƒç»„å¥åº·: %d/%d", healthyCount, len(endpointsToCheck)))
	} else {
		slog.Debug(fmt.Sprintf("ğŸ©º [å¥åº·æ£€æŸ¥] å®Œæˆæ£€æŸ¥ - æ€»ä½“å¥åº·: %d/%d", healthyCount, len(endpointsToCheck)))
	}

	// v5.0+ Wails æ¡Œé¢åº”ç”¨ï¼šå®šæ—¶å¥åº·æ£€æŸ¥å®Œæˆåè§¦å‘å›è°ƒæ¨é€äº‹ä»¶
	if m.onHealthCheckComplete != nil {
		go m.onHealthCheckComplete()
	}
}

// checkEndpointHealth checks the health of a single endpoint
func (m *Manager) checkEndpointHealth(endpoint *Endpoint) {
	start := time.Now()
	
	healthURL := endpoint.Config.URL + m.config.Health.HealthPath
	req, err := http.NewRequestWithContext(m.ctx, "GET", healthURL, nil)
	if err != nil {
		m.updateEndpointStatus(endpoint, false, 0)
		return
	}

	// Add authorization header with dynamically resolved token
	token := m.GetTokenForEndpoint(endpoint)
	if token != "" {
		req.Header.Set("Authorization", "Bearer "+token)
	}

	resp, err := m.client.Do(req)
	responseTime := time.Since(start)
	
	if err != nil {
		// Network or connection error
		slog.Warn(fmt.Sprintf("âŒ [å¥åº·æ£€æŸ¥] ç«¯ç‚¹ç½‘ç»œé”™è¯¯: %s - é”™è¯¯: %s, å“åº”æ—¶é—´: %dms", 
			endpoint.Config.Name, err.Error(), responseTime.Milliseconds()))
		m.updateEndpointStatus(endpoint, false, responseTime)
		return
	}
	
	resp.Body.Close()
	
	// Only consider 2xx as healthy for API endpoints
	// 2xx: Success responses only
	// All other status codes (including 4xx, 5xx) are considered unhealthy
	healthy := (resp.StatusCode >= 200 && resp.StatusCode < 300)
	
	// Log health check results
	if healthy {
		slog.Debug(fmt.Sprintf("âœ… [å¥åº·æ£€æŸ¥] ç«¯ç‚¹æ­£å¸¸: %s - çŠ¶æ€ç : %d, å“åº”æ—¶é—´: %dms",
			endpoint.Config.Name,
			resp.StatusCode,
			responseTime.Milliseconds()))
	} else {
		slog.Warn(fmt.Sprintf("âš ï¸ [å¥åº·æ£€æŸ¥] ç«¯ç‚¹å¼‚å¸¸: %s - çŠ¶æ€ç : %d, å“åº”æ—¶é—´: %dms",
			endpoint.Config.Name,
			resp.StatusCode,
			responseTime.Milliseconds()))
	}
	
	m.updateEndpointStatus(endpoint, healthy, responseTime)
}

// updateEndpointStatus updates the health status of an endpoint
func (m *Manager) updateEndpointStatus(endpoint *Endpoint, healthy bool, responseTime time.Duration) {
	endpoint.mutex.Lock()
	defer endpoint.mutex.Unlock()

	endpoint.Status.LastCheck = time.Now()
	endpoint.Status.ResponseTime = responseTime
	endpoint.Status.NeverChecked = false // æ ‡è®°ä¸ºå·²æ£€æµ‹

	if healthy {
		// Endpoint is healthy
		wasUnhealthy := !endpoint.Status.Healthy
		endpoint.Status.Healthy = true
		endpoint.Status.ConsecutiveFails = 0

		// Log recovery if endpoint was previously unhealthy
		if wasUnhealthy {
			slog.Info(fmt.Sprintf("âœ… [å¥åº·æ£€æŸ¥] ç«¯ç‚¹æ¢å¤æ­£å¸¸: %s - å“åº”æ—¶é—´: %dms",
				endpoint.Config.Name, responseTime.Milliseconds()))
		}
	} else {
		// Endpoint failed health check
		endpoint.Status.ConsecutiveFails++
		wasHealthy := endpoint.Status.Healthy

		// Mark as unhealthy immediately on any failure
		endpoint.Status.Healthy = false

		// Log the failure
		if wasHealthy {
			slog.Warn(fmt.Sprintf("âŒ [å¥åº·æ£€æŸ¥] ç«¯ç‚¹æ ‡è®°ä¸ºä¸å¯ç”¨: %s - è¿ç»­å¤±è´¥: %dæ¬¡, å“åº”æ—¶é—´: %dms",
				endpoint.Config.Name, endpoint.Status.ConsecutiveFails, responseTime.Milliseconds()))
		} else {
			slog.Debug(fmt.Sprintf("âŒ [å¥åº·æ£€æŸ¥] ç«¯ç‚¹ä»ç„¶ä¸å¯ç”¨: %s - è¿ç»­å¤±è´¥: %dæ¬¡, å“åº”æ—¶é—´: %dms",
				endpoint.Config.Name, endpoint.Status.ConsecutiveFails, responseTime.Milliseconds()))
		}
	}

	// é€šçŸ¥Webç•Œé¢ç«¯ç‚¹çŠ¶æ€å˜åŒ–
	go m.notifyWebInterface(endpoint)

	// v4.0: ç»„å¥åº·ç»Ÿè®¡å·²ç¦ç”¨ï¼Œå‰ç«¯ä¸å†éœ€è¦
	// é€šçŸ¥ç»„å¥åº·ç»Ÿè®¡å˜åŒ–
	// go m.notifyGroupHealthStats(endpoint.Config.Group)
}

// IsHealthy returns the health status of an endpoint
func (e *Endpoint) IsHealthy() bool {
	e.mutex.RLock()
	defer e.mutex.RUnlock()
	return e.Status.Healthy
}

// GetResponseTime returns the last response time of an endpoint
func (e *Endpoint) GetResponseTime() time.Duration {
	e.mutex.RLock()
	defer e.mutex.RUnlock()
	return e.Status.ResponseTime
}

// GetStatus returns a copy of the endpoint status
func (e *Endpoint) GetStatus() EndpointStatus {
	e.mutex.RLock()
	defer e.mutex.RUnlock()
	return e.Status
}

// GetEndpoints returns all endpoints for Web interface
func (m *Manager) GetEndpoints() []*Endpoint {
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()

	result := make([]*Endpoint, len(m.endpoints))
	copy(result, m.endpoints)
	return result
}

// GetEndpointStatus returns the status of an endpoint by name
func (m *Manager) GetEndpointStatus(name string) EndpointStatus {
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()

	for _, ep := range m.endpoints {
		if ep.Config.Name == name {
			ep.mutex.RLock()
			status := ep.Status
			ep.mutex.RUnlock()
			return status
		}
	}
	return EndpointStatus{}
}

// UpdateEndpointPriority updates the priority of an endpoint by name
func (m *Manager) UpdateEndpointPriority(name string, newPriority int) error {
	if newPriority < 1 {
		return fmt.Errorf("ä¼˜å…ˆçº§å¿…é¡»å¤§äºç­‰äº1")
	}

	m.endpointsMu.RLock()
	// Find the endpoint
	var targetEndpoint *Endpoint
	for _, ep := range m.endpoints {
		if ep.Config.Name == name {
			targetEndpoint = ep
			break
		}
	}
	m.endpointsMu.RUnlock()

	if targetEndpoint == nil {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªæ‰¾åˆ°", name)
	}

	// Update the priority
	targetEndpoint.Config.Priority = newPriority

	// Update the config as well
	for i, epConfig := range m.config.Endpoints {
		if epConfig.Name == name {
			m.config.Endpoints[i].Priority = newPriority
			break
		}
	}

	slog.Info(fmt.Sprintf("ğŸ”„ ç«¯ç‚¹ä¼˜å…ˆçº§å·²æ›´æ–°: %s -> %d", name, newPriority))
	
	return nil
}

// ManualHealthCheck performs a manual health check on a specific endpoint by name
func (m *Manager) ManualHealthCheck(endpointName string) error {
	var targetEndpoint *Endpoint

	// v5.0+: ä½¿ç”¨è¯»é”æŸ¥æ‰¾ç«¯ç‚¹
	m.endpointsMu.RLock()
	for _, endpoint := range m.endpoints {
		if endpoint.Config.Name == endpointName {
			targetEndpoint = endpoint
			break
		}
	}
	m.endpointsMu.RUnlock()

	if targetEndpoint == nil {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªæ‰¾åˆ°", endpointName)
	}

	// Perform health check on the endpoint
	slog.Info(fmt.Sprintf("ğŸ” [æ‰‹åŠ¨æ£€æŸ¥] å¼€å§‹æ£€æŸ¥ç«¯ç‚¹: %s", endpointName))
	m.checkEndpointHealth(targetEndpoint)

	// Get status and log completion with response time
	status := targetEndpoint.Status
	healthStatus := "å¥åº·"
	if !status.Healthy {
		if status.NeverChecked {
			healthStatus = "æœªæ£€æµ‹"
		} else {
			healthStatus = "ä¸å¥åº·"
		}
	}

	slog.Info(fmt.Sprintf("ğŸ” [æ‰‹åŠ¨æ£€æŸ¥] æ£€æŸ¥å®Œæˆ: %s - çŠ¶æ€: %s, å“åº”æ—¶é—´: %s",
		endpointName, healthStatus, utils.FormatResponseTime(status.ResponseTime)))

	return nil
}

// BatchHealthCheckAll æ‰¹é‡æ£€æµ‹æ‰€æœ‰ç«¯ç‚¹çš„å¥åº·çŠ¶æ€
// å¹¶å‘æ‰§è¡Œæ‰€æœ‰ç«¯ç‚¹çš„å¥åº·æ£€æŸ¥ï¼Œæé«˜æ•ˆç‡
// ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…èµ„æºè€—å°½
func (m *Manager) BatchHealthCheckAll() (int, int, error) {
	slog.Info("ğŸ” [æ‰¹é‡å¥åº·æ£€æµ‹] å¼€å§‹æ£€æµ‹æ‰€æœ‰ç«¯ç‚¹")

	// v5.0+: ä½¿ç”¨å¿«ç…§æœºåˆ¶è·å–ç«¯ç‚¹åˆ—è¡¨
	m.endpointsMu.RLock()
	endpoints := make([]*Endpoint, len(m.endpoints))
	copy(endpoints, m.endpoints)
	m.endpointsMu.RUnlock()

	if len(endpoints) == 0 {
		return 0, 0, fmt.Errorf("æ²¡æœ‰é…ç½®ä»»ä½•ç«¯ç‚¹")
	}

	slog.Info(fmt.Sprintf("   å…±æœ‰ %d ä¸ªç«¯ç‚¹éœ€è¦æ£€æµ‹", len(endpoints)))

	// ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°é‡ï¼ˆæœ€å¤š 20 ä¸ªå¹¶å‘ï¼‰
	const maxConcurrentChecks = 20
	semaphore := make(chan struct{}, maxConcurrentChecks)

	// ä½¿ç”¨ WaitGroup å¹¶å‘æ£€æµ‹æ‰€æœ‰ç«¯ç‚¹
	var wg sync.WaitGroup
	var healthyCount, unhealthyCount int
	var countMu sync.Mutex

	for _, endpoint := range endpoints {
		wg.Add(1)
		semaphore <- struct{}{} // è·å–ä¿¡å·é‡

		go func(ep *Endpoint) {
			defer wg.Done()
			defer func() { <-semaphore }() // é‡Šæ”¾ä¿¡å·é‡

			// æ‰§è¡Œå¥åº·æ£€æµ‹ï¼ˆå¤ç”¨ç°æœ‰æ–¹æ³•ï¼‰
			m.checkEndpointHealth(ep)

			// è·å–æ£€æµ‹ç»“æœï¼ˆéœ€è¦åŠ é”è¯»å–ï¼‰
			ep.mutex.RLock()
			healthy := ep.Status.Healthy
			responseTime := ep.Status.ResponseTime
			ep.mutex.RUnlock()

			// ç»Ÿè®¡æ£€æµ‹ç»“æœ
			countMu.Lock()
			if healthy {
				healthyCount++
			} else {
				unhealthyCount++
			}
			countMu.Unlock()

			// è®°å½•æ£€æµ‹ç»“æœ
			healthStatus := "âŒ ä¸å¥åº·"
			if healthy {
				healthStatus = "âœ… å¥åº·"
			}
			slog.Debug(fmt.Sprintf("   æ£€æµ‹ç«¯ç‚¹: %s - çŠ¶æ€: %s, å“åº”æ—¶é—´: %s",
				ep.Config.Name,
				healthStatus,
				utils.FormatResponseTime(responseTime),
			))
		}(endpoint)
	}

	// ç­‰å¾…æ‰€æœ‰æ£€æµ‹å®Œæˆ
	wg.Wait()

	slog.Info(fmt.Sprintf("âœ… [æ‰¹é‡å¥åº·æ£€æµ‹] å®Œæˆï¼Œå…±æ£€æµ‹ %d ä¸ªç«¯ç‚¹ (å¥åº·: %d, ä¸å¥åº·: %d)",
		len(endpoints), healthyCount, unhealthyCount))

	return healthyCount, unhealthyCount, nil
}

// ==================== å¤š API Key åˆ‡æ¢åŠŸèƒ½ ====================

// GetKeyManager è¿”å› Key ç®¡ç†å™¨
func (m *Manager) GetKeyManager() *KeyManager {
	return m.keyManager
}

// SwitchEndpointToken åˆ‡æ¢ç«¯ç‚¹çš„ Token
func (m *Manager) SwitchEndpointToken(endpointName string, index int) error {
	// éªŒè¯ç«¯ç‚¹å­˜åœ¨
	ep := m.GetEndpointByNameAny(endpointName)
	if ep == nil {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªæ‰¾åˆ°", endpointName)
	}

	// éªŒè¯è¯¥ç«¯ç‚¹æ”¯æŒå¤š Token
	if len(ep.Config.Tokens) == 0 {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªé…ç½®å¤š Token", endpointName)
	}

	err := m.keyManager.SwitchToken(endpointName, index)
	if err != nil {
		return err
	}

	// è·å–åˆ‡æ¢åçš„ Token åç§°ç”¨äºæ—¥å¿—
	tokenName := ""
	if index >= 0 && index < len(ep.Config.Tokens) {
		tokenName = ep.Config.Tokens[index].Name
		if tokenName == "" {
			tokenName = fmt.Sprintf("Token %d", index+1)
		}
	}

	slog.Info(fmt.Sprintf("ğŸ”‘ [Keyåˆ‡æ¢] ç«¯ç‚¹ %s çš„ Token å·²åˆ‡æ¢åˆ°: %s (ç´¢å¼•: %d)", endpointName, tokenName, index))

	// å‘å¸ƒäº‹ä»¶é€šçŸ¥
	if m.eventBus != nil {
		m.eventBus.Publish(events.Event{
			Type:     "endpoint_key_changed",
			Source:   "key_manager",
			Priority: events.PriorityHigh,
			Data: map[string]interface{}{
				"endpoint":   endpointName,
				"key_type":   "token",
				"new_index":  index,
				"key_name":   tokenName,
				"timestamp":  time.Now().Format("2006-01-02 15:04:05"),
			},
		})
	}

	return nil
}

// SwitchEndpointApiKey åˆ‡æ¢ç«¯ç‚¹çš„ API Key
func (m *Manager) SwitchEndpointApiKey(endpointName string, index int) error {
	ep := m.GetEndpointByNameAny(endpointName)
	if ep == nil {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªæ‰¾åˆ°", endpointName)
	}

	if len(ep.Config.ApiKeys) == 0 {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªé…ç½®å¤š API Key", endpointName)
	}

	err := m.keyManager.SwitchApiKey(endpointName, index)
	if err != nil {
		return err
	}

	// è·å–åˆ‡æ¢åçš„ API Key åç§°ç”¨äºæ—¥å¿—
	keyName := ""
	if index >= 0 && index < len(ep.Config.ApiKeys) {
		keyName = ep.Config.ApiKeys[index].Name
		if keyName == "" {
			keyName = fmt.Sprintf("API Key %d", index+1)
		}
	}

	slog.Info(fmt.Sprintf("ğŸ”‘ [Keyåˆ‡æ¢] ç«¯ç‚¹ %s çš„ API Key å·²åˆ‡æ¢åˆ°: %s (ç´¢å¼•: %d)", endpointName, keyName, index))

	if m.eventBus != nil {
		m.eventBus.Publish(events.Event{
			Type:     "endpoint_key_changed",
			Source:   "key_manager",
			Priority: events.PriorityHigh,
			Data: map[string]interface{}{
				"endpoint":   endpointName,
				"key_type":   "api_key",
				"new_index":  index,
				"key_name":   keyName,
				"timestamp":  time.Now().Format("2006-01-02 15:04:05"),
			},
		})
	}

	return nil
}

// GetEndpointKeysInfo è·å–ç«¯ç‚¹çš„ Key ä¿¡æ¯ï¼ˆç”¨äº APIï¼ŒKey å€¼è„±æ•ï¼‰
func (m *Manager) GetEndpointKeysInfo(endpointName string) map[string]interface{} {
	ep := m.GetEndpointByNameAny(endpointName)
	if ep == nil {
		return nil
	}

	state := m.keyManager.GetEndpointKeyState(endpointName)

	// æ„å»º Token åˆ—è¡¨ï¼ˆè„±æ•ï¼‰
	tokens := make([]map[string]interface{}, 0)
	for i, t := range ep.Config.Tokens {
		tokens = append(tokens, map[string]interface{}{
			"index":     i,
			"name":      t.Name,
			"masked":    maskKey(t.Value),
			"is_active": state != nil && state.ActiveTokenIndex == i,
		})
	}
	// å• Token æƒ…å†µ
	if len(tokens) == 0 && ep.Config.Token != "" {
		tokens = append(tokens, map[string]interface{}{
			"index":     0,
			"name":      "default",
			"masked":    maskKey(ep.Config.Token),
			"is_active": true,
		})
	}

	// æ„å»º API Key åˆ—è¡¨ï¼ˆè„±æ•ï¼‰
	apiKeys := make([]map[string]interface{}, 0)
	for i, k := range ep.Config.ApiKeys {
		apiKeys = append(apiKeys, map[string]interface{}{
			"index":     i,
			"name":      k.Name,
			"masked":    maskKey(k.Value),
			"is_active": state != nil && state.ActiveApiKeyIndex == i,
		})
	}
	if len(apiKeys) == 0 && ep.Config.ApiKey != "" {
		apiKeys = append(apiKeys, map[string]interface{}{
			"index":     0,
			"name":      "default",
			"masked":    maskKey(ep.Config.ApiKey),
			"is_active": true,
		})
	}

	result := map[string]interface{}{
		"endpoint":           endpointName,
		"tokens":             tokens,
		"api_keys":           apiKeys,
		"supports_switching": len(ep.Config.Tokens) > 1 || len(ep.Config.ApiKeys) > 1,
	}

	if state != nil && !state.LastSwitchTime.IsZero() {
		result["last_switch_time"] = state.LastSwitchTime.Format("2006-01-02 15:04:05")
	}

	return result
}

// maskKey è„±æ• Key å€¼ï¼Œåªæ˜¾ç¤ºå‰4ä½å’Œå4ä½
func maskKey(key string) string {
	if len(key) <= 8 {
		return "****"
	}
	return key[:4] + "****" + key[len(key)-4:]
}

// ==================== v5.0+ åŠ¨æ€ç«¯ç‚¹ç®¡ç†åŠŸèƒ½ ====================

// SyncEndpoints ä»æ•°æ®åº“åŒæ­¥ç«¯ç‚¹ï¼ˆv5.0 Desktop ä¸“ç”¨ï¼‰
// ç”¨äºå¯åŠ¨æ—¶ä»æ•°æ®åº“åŠ è½½ç«¯ç‚¹ï¼Œæ›¿æ¢ç°æœ‰ç«¯ç‚¹åˆ—è¡¨
func (m *Manager) SyncEndpoints(configs []config.EndpointConfig) {
	// åˆ›å»ºæ–°ç«¯ç‚¹åˆ—è¡¨
	endpoints := make([]*Endpoint, len(configs))
	for i, cfg := range configs {
		endpoints[i] = &Endpoint{
			Config: cfg,
			Status: EndpointStatus{
				Healthy:      false,
				LastCheck:    time.Now(),
				NeverChecked: true,
			},
		}

		// åˆå§‹åŒ– Key ç®¡ç†çŠ¶æ€
		tokenCount := len(cfg.Tokens)
		if tokenCount == 0 && cfg.Token != "" {
			tokenCount = 1
		}
		apiKeyCount := len(cfg.ApiKeys)
		if apiKeyCount == 0 && cfg.ApiKey != "" {
			apiKeyCount = 1
		}
		m.keyManager.InitEndpoint(cfg.Name, tokenCount, apiKeyCount)
	}

	// ä½¿ç”¨å†™é”æ›¿æ¢ç«¯ç‚¹åˆ—è¡¨
	m.endpointsMu.Lock()
	m.endpoints = endpoints
	m.endpointsMu.Unlock()

	// æ›´æ–° GroupManagerï¼ˆåˆ›å»ºç»„ï¼‰
	m.groupManager.UpdateGroups(endpoints)

	slog.Info(fmt.Sprintf("ğŸ”„ [ç«¯ç‚¹åŒæ­¥] å·²åŒæ­¥ %d ä¸ªç«¯ç‚¹åˆ°ç®¡ç†å™¨", len(configs)))
}

// AddEndpoint åŠ¨æ€æ·»åŠ ç«¯ç‚¹ï¼ˆv5.0+ æ–°å¢ï¼‰
// çº¿ç¨‹å®‰å…¨åœ°å°†æ–°ç«¯ç‚¹æ·»åŠ åˆ°ç®¡ç†å™¨ä¸­
func (m *Manager) AddEndpoint(cfg config.EndpointConfig) error {
	// éªŒè¯ç«¯ç‚¹åç§°å”¯ä¸€æ€§
	m.endpointsMu.RLock()
	for _, ep := range m.endpoints {
		if ep.Config.Name == cfg.Name {
			m.endpointsMu.RUnlock()
			return fmt.Errorf("ç«¯ç‚¹ '%s' å·²å­˜åœ¨", cfg.Name)
		}
	}
	m.endpointsMu.RUnlock()

	// åˆ›å»ºæ–°ç«¯ç‚¹
	endpoint := &Endpoint{
		Config: cfg,
		Status: EndpointStatus{
			Healthy:      false, // æ‚²è§‚åˆå§‹åŒ–ï¼Œç­‰å¾…å¥åº·æ£€æŸ¥
			LastCheck:    time.Now(),
			NeverChecked: true,
		},
	}

	// åˆå§‹åŒ– Key ç®¡ç†çŠ¶æ€
	tokenCount := len(cfg.Tokens)
	if tokenCount == 0 && cfg.Token != "" {
		tokenCount = 1
	}
	apiKeyCount := len(cfg.ApiKeys)
	if apiKeyCount == 0 && cfg.ApiKey != "" {
		apiKeyCount = 1
	}
	m.keyManager.InitEndpoint(cfg.Name, tokenCount, apiKeyCount)

	// ä½¿ç”¨å†™é”æ·»åŠ ç«¯ç‚¹
	m.endpointsMu.Lock()
	m.endpoints = append(m.endpoints, endpoint)
	m.endpointsMu.Unlock()

	// æ›´æ–° GroupManager
	m.endpointsMu.RLock()
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)
	m.endpointsMu.RUnlock()
	m.groupManager.UpdateGroups(snapshot)

	// ç«‹å³è§¦å‘å¥åº·æ£€æŸ¥
	go m.checkEndpointHealth(endpoint)

	// å‘å¸ƒäº‹ä»¶é€šçŸ¥
	if m.eventBus != nil {
		m.eventBus.Publish(events.Event{
			Type:     "endpoint_added",
			Source:   "endpoint_manager",
			Priority: events.PriorityHigh,
			Data: map[string]interface{}{
				"name":      cfg.Name,
				"url":       cfg.URL,
				"priority":  cfg.Priority,
				"timestamp": time.Now().Format("2006-01-02 15:04:05"),
			},
		})
	}

	slog.Info(fmt.Sprintf("â• [ç«¯ç‚¹ç®¡ç†] æ–°å¢ç«¯ç‚¹: %s (%s)", cfg.Name, cfg.URL))
	return nil
}

// RemoveEndpoint åŠ¨æ€ç§»é™¤ç«¯ç‚¹ï¼ˆv5.0+ æ–°å¢ï¼‰
// çº¿ç¨‹å®‰å…¨åœ°ä»ç®¡ç†å™¨ä¸­ç§»é™¤ç«¯ç‚¹
func (m *Manager) RemoveEndpoint(name string) error {
	m.endpointsMu.Lock()
	defer m.endpointsMu.Unlock()

	// æŸ¥æ‰¾å¹¶ç§»é™¤ç«¯ç‚¹
	index := -1
	for i, ep := range m.endpoints {
		if ep.Config.Name == name {
			index = i
			break
		}
	}

	if index == -1 {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªæ‰¾åˆ°", name)
	}

	// ç§»é™¤ç«¯ç‚¹ï¼ˆä¿æŒåˆ‡ç‰‡é¡ºåºï¼‰
	removedEndpoint := m.endpoints[index]
	m.endpoints = append(m.endpoints[:index], m.endpoints[index+1:]...)

	// æ¸…ç† KeyManager çŠ¶æ€
	m.keyManager.RemoveEndpoint(name)

	// æ›´æ–° GroupManagerï¼ˆåœ¨é”å†…åˆ›å»ºå¿«ç…§ï¼‰
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)

	// åœ¨é”å¤–æ›´æ–° GroupManager
	go func() {
		m.groupManager.UpdateGroups(snapshot)
	}()

	// å‘å¸ƒäº‹ä»¶é€šçŸ¥
	if m.eventBus != nil {
		m.eventBus.Publish(events.Event{
			Type:     "endpoint_removed",
			Source:   "endpoint_manager",
			Priority: events.PriorityHigh,
			Data: map[string]interface{}{
				"name":      name,
				"url":       removedEndpoint.Config.URL,
				"timestamp": time.Now().Format("2006-01-02 15:04:05"),
			},
		})
	}

	slog.Info(fmt.Sprintf("â– [ç«¯ç‚¹ç®¡ç†] ç§»é™¤ç«¯ç‚¹: %s", name))
	return nil
}

// UpdateEndpointConfig æ›´æ–°ç«¯ç‚¹é…ç½®ï¼ˆv5.0+ æ–°å¢ï¼‰
// æ›´æ–°ç°æœ‰ç«¯ç‚¹çš„é…ç½®ï¼ˆä¸åŒ…æ‹¬åç§°ï¼‰
func (m *Manager) UpdateEndpointConfig(name string, cfg config.EndpointConfig) error {
	m.endpointsMu.RLock()
	var targetEndpoint *Endpoint
	for _, ep := range m.endpoints {
		if ep.Config.Name == name {
			targetEndpoint = ep
			break
		}
	}
	m.endpointsMu.RUnlock()

	if targetEndpoint == nil {
		return fmt.Errorf("ç«¯ç‚¹ '%s' æœªæ‰¾åˆ°", name)
	}

	// ä¿ç•™åŸåç§°
	cfg.Name = name

	// æ›´æ–°é…ç½®
	targetEndpoint.mutex.Lock()
	targetEndpoint.Config = cfg
	targetEndpoint.mutex.Unlock()

	// æ›´æ–° Key ç®¡ç†çŠ¶æ€
	tokenCount := len(cfg.Tokens)
	if tokenCount == 0 && cfg.Token != "" {
		tokenCount = 1
	}
	apiKeyCount := len(cfg.ApiKeys)
	if apiKeyCount == 0 && cfg.ApiKey != "" {
		apiKeyCount = 1
	}
	m.keyManager.UpdateEndpointKeyCount(name, tokenCount, apiKeyCount)

	// æ›´æ–° GroupManager
	m.endpointsMu.RLock()
	snapshot := make([]*Endpoint, len(m.endpoints))
	copy(snapshot, m.endpoints)
	m.endpointsMu.RUnlock()
	m.groupManager.UpdateGroups(snapshot)

	// ç«‹å³è§¦å‘å¥åº·æ£€æŸ¥
	go m.checkEndpointHealth(targetEndpoint)

	// å‘å¸ƒäº‹ä»¶é€šçŸ¥
	if m.eventBus != nil {
		m.eventBus.Publish(events.Event{
			Type:     "endpoint_updated",
			Source:   "endpoint_manager",
			Priority: events.PriorityHigh,
			Data: map[string]interface{}{
				"name":      name,
				"url":       cfg.URL,
				"priority":  cfg.Priority,
				"timestamp": time.Now().Format("2006-01-02 15:04:05"),
			},
		})
	}

	slog.Info(fmt.Sprintf("âœï¸ [ç«¯ç‚¹ç®¡ç†] æ›´æ–°ç«¯ç‚¹é…ç½®: %s", name))
	return nil
}

// GetEndpointCount è¿”å›å½“å‰ç«¯ç‚¹æ•°é‡ï¼ˆv5.0+ æ–°å¢ï¼‰
func (m *Manager) GetEndpointCount() int {
	m.endpointsMu.RLock()
	defer m.endpointsMu.RUnlock()
	return len(m.endpoints)
}