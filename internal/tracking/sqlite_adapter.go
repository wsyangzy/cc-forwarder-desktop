package tracking

import (
	"context"
	"database/sql"
	"embed"
	"fmt"
	"log/slog"
	"os"
	"path/filepath"
	"runtime"
	"strings"
	"time"

	_ "modernc.org/sqlite"
)

//go:embed schema.sql
var sqliteSchemaFS embed.FS

// SQLiteAdapter SQLiteæ•°æ®åº“é€‚é…å™¨å®ç°ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
type SQLiteAdapter struct {
	config   DatabaseConfig
	db       *sql.DB
	logger   *slog.Logger
	location *time.Location // é…ç½®çš„æ—¶åŒº
}

// NewSQLiteAdapter åˆ›å»ºSQLiteé€‚é…å™¨å®ä¾‹
func NewSQLiteAdapter(config DatabaseConfig) (*SQLiteAdapter, error) {
	// è®¾ç½®é»˜è®¤é…ç½®
	setDefaultConfig(&config)

	// è§£ææ—¶åŒºé…ç½®
	timezone := strings.TrimSpace(config.Timezone)
	if timezone == "" {
		timezone = "Asia/Shanghai" // é»˜è®¤æ—¶åŒº
	}

	location, err := time.LoadLocation(timezone)
	if err != nil {
		// å¦‚æœæ—¶åŒºè§£æå¤±è´¥ï¼Œè®°å½•é”™è¯¯ä½†ä¸ç»ˆæ­¢ï¼Œä½¿ç”¨ç³»ç»Ÿæœ¬åœ°æ—¶åŒº
		location = time.Local
		slog.Warn("SQLiteæ—¶åŒºè§£æå¤±è´¥ï¼Œä½¿ç”¨ç³»ç»Ÿæœ¬åœ°æ—¶åŒº",
			"configured_timezone", timezone,
			"error", err,
			"fallback_timezone", location.String())
	} else {
		slog.Info("SQLiteæ—¶åŒºé…ç½®æˆåŠŸ", "timezone", timezone)
	}

	adapter := &SQLiteAdapter{
		config:   config,
		logger:   slog.Default(),
		location: location,
	}

	return adapter, nil
}

// Open å»ºç«‹SQLiteæ•°æ®åº“è¿æ¥
func (s *SQLiteAdapter) Open() error {
	dbPath := s.config.DatabasePath
	if dbPath == "" {
		// ä½¿ç”¨è·¨å¹³å°ç”¨æˆ·ç›®å½•ä½œä¸ºé»˜è®¤è·¯å¾„
		// Windows: %APPDATA%\CC-Forwarder\data\cc-forwarder.db
		// macOS: ~/Library/Application Support/CC-Forwarder/data/cc-forwarder.db
		// Linux: ~/.local/share/cc-forwarder/data/cc-forwarder.db
		dbPath = filepath.Join(getSQLiteAppDataDir(), "data", "cc-forwarder.db")
		s.logger.Info("ä½¿ç”¨é»˜è®¤æ•°æ®åº“è·¯å¾„", "path", dbPath)
	}

	s.logger.Info("æ­£åœ¨è¿æ¥SQLiteæ•°æ®åº“", "path", dbPath)

	// ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
	if dbPath != ":memory:" {
		dbDir := filepath.Dir(dbPath)
		if err := os.MkdirAll(dbDir, 0755); err != nil {
			return fmt.Errorf("failed to create database directory: %w", err)
		}
	}

	// æ„å»ºSQLiteè¿æ¥å­—ç¬¦ä¸²
	dsn := dbPath + "?_journal_mode=WAL&_synchronous=NORMAL&_cache_size=10000&_foreign_keys=1&_busy_timeout=60000"

	db, err := sql.Open("sqlite", dsn)
	if err != nil {
		return fmt.Errorf("failed to open SQLite database: %w", err)
	}

	// è®¾ç½®è¿æ¥æ± å‚æ•°ï¼ˆSQLiteå»ºè®®å°‘é‡è¿æ¥ï¼‰
	db.SetMaxOpenConns(1) // SQLiteå†™æ“ä½œéœ€è¦å•ä¸€è¿æ¥
	db.SetMaxIdleConns(1)
	db.SetConnMaxLifetime(0)

	// æµ‹è¯•è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
	defer cancel()

	if err := db.PingContext(ctx); err != nil {
		db.Close()
		return fmt.Errorf("failed to ping SQLite database: %w", err)
	}

	s.db = db

	// è¯Šæ–­æ—¶åŒºè®¾ç½®
	s.diagnoseTimezoneSettings()

	s.logger.Info("âœ… SQLiteæ•°æ®åº“è¿æ¥æˆåŠŸ")

	return nil
}

// Close å…³é—­æ•°æ®åº“è¿æ¥
func (s *SQLiteAdapter) Close() error {
	if s.db != nil {
		s.logger.Info("æ­£åœ¨å…³é—­SQLiteæ•°æ®åº“è¿æ¥")
		return s.db.Close()
	}
	return nil
}

// Ping æµ‹è¯•æ•°æ®åº“è¿æ¥
func (s *SQLiteAdapter) Ping(ctx context.Context) error {
	if s.db == nil {
		return fmt.Errorf("database not connected")
	}
	return s.db.PingContext(ctx)
}

// GetDB è·å–æ•°æ®åº“è¿æ¥
func (s *SQLiteAdapter) GetDB() *sql.DB {
	return s.db
}

// GetReadDB è·å–è¯»æ•°æ®åº“è¿æ¥
func (s *SQLiteAdapter) GetReadDB() *sql.DB {
	return s.db
}

// GetWriteDB è·å–å†™æ•°æ®åº“è¿æ¥
func (s *SQLiteAdapter) GetWriteDB() *sql.DB {
	return s.db
}

// BeginTx å¼€å§‹äº‹åŠ¡
func (s *SQLiteAdapter) BeginTx(ctx context.Context, opts *sql.TxOptions) (*sql.Tx, error) {
	if s.db == nil {
		return nil, fmt.Errorf("database not connected")
	}
	return s.db.BeginTx(ctx, opts)
}

// InitSchema åˆå§‹åŒ–SQLiteæ•°æ®åº“Schema
func (s *SQLiteAdapter) InitSchema() error {
	ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
	defer cancel()

	s.logger.Info("æ­£åœ¨åˆå§‹åŒ–SQLiteæ•°æ®åº“Schema")

	// è¯»å–å¹¶æ‰§è¡ŒSQLite schema
	schema, err := sqliteSchemaFS.ReadFile("schema.sql")
	if err != nil {
		return fmt.Errorf("failed to read schema.sql: %w", err)
	}

	// SQLiteå¯ä»¥ç›´æ¥æ‰§è¡Œæ•´ä¸ªschema
	if _, err := s.db.ExecContext(ctx, string(schema)); err != nil {
		return fmt.Errorf("failed to execute schema: %w", err)
	}

	// v5.0.1+: æ‰§è¡Œè¿ç§»æ·»åŠ æ–°å­—æ®µ
	if err := s.migrateSchema(ctx); err != nil {
		return fmt.Errorf("failed to migrate schema: %w", err)
	}

	s.logger.Info("âœ… SQLiteæ•°æ®åº“Schemaåˆå§‹åŒ–å®Œæˆ")
	return nil
}

// migrateSchema æ‰§è¡Œæ•°æ®åº“è¿ç§»ï¼ˆv5.0.1+: æ·»åŠ  5m/1h ç¼“å­˜å­—æ®µï¼‰
func (s *SQLiteAdapter) migrateSchema(ctx context.Context) error {
	// request_logs è¿ç§»ï¼šå†å²ä¸Šå…ˆä¸Šçº¿ usage trackingï¼Œåç»­è¡¥å……ç¼“å­˜å­—æ®µ
	requestLogMigrations := []struct {
		checkColumn string
		alterSQL    string
		description string
	}{
		{
			checkColumn: "cache_creation_5m_tokens",
			alterSQL:    "ALTER TABLE request_logs ADD COLUMN cache_creation_5m_tokens INTEGER DEFAULT 0",
			description: "5åˆ†é’Ÿç¼“å­˜åˆ›å»ºtokenså­—æ®µ",
		},
		{
			checkColumn: "cache_creation_1h_tokens",
			alterSQL:    "ALTER TABLE request_logs ADD COLUMN cache_creation_1h_tokens INTEGER DEFAULT 0",
			description: "1å°æ—¶ç¼“å­˜åˆ›å»ºtokenså­—æ®µ",
		},
		{
			checkColumn: "cache_creation_5m_cost_usd",
			alterSQL:    "ALTER TABLE request_logs ADD COLUMN cache_creation_5m_cost_usd REAL DEFAULT 0",
			description: "5åˆ†é’Ÿç¼“å­˜åˆ›å»ºæˆæœ¬å­—æ®µ",
		},
		{
			checkColumn: "cache_creation_1h_cost_usd",
			alterSQL:    "ALTER TABLE request_logs ADD COLUMN cache_creation_1h_cost_usd REAL DEFAULT 0",
			description: "1å°æ—¶ç¼“å­˜åˆ›å»ºæˆæœ¬å­—æ®µ",
		},
	}

	// endpoints è¿ç§»ï¼šç«¯ç‚¹å­˜å‚¨è¡¨è¿­ä»£æ–°å¢å­—æ®µæ—¶ï¼Œéœ€è¦å…¼å®¹æ—§ dbï¼ˆCREATE TABLE IF NOT EXISTS ä¸ä¼šè¡¥åˆ—ï¼‰
	endpointsMigrations := []struct {
		checkColumn string
		alterSQL    string
		description string
	}{
		{
			checkColumn: "timeout_seconds",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN timeout_seconds INTEGER DEFAULT 300",
			description: "ç«¯ç‚¹è¶…æ—¶å­—æ®µ",
		},
		{
			checkColumn: "supports_count_tokens",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN supports_count_tokens INTEGER DEFAULT 0",
			description: "ç«¯ç‚¹ supports_count_tokens å­—æ®µ",
		},
		{
			checkColumn: "cost_multiplier",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN cost_multiplier REAL DEFAULT 1.0",
			description: "ç«¯ç‚¹æ€»æˆæœ¬å€ç‡å­—æ®µ",
		},
		{
			checkColumn: "input_cost_multiplier",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN input_cost_multiplier REAL DEFAULT 1.0",
			description: "ç«¯ç‚¹è¾“å…¥æˆæœ¬å€ç‡å­—æ®µ",
		},
		{
			checkColumn: "output_cost_multiplier",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN output_cost_multiplier REAL DEFAULT 1.0",
			description: "ç«¯ç‚¹è¾“å‡ºæˆæœ¬å€ç‡å­—æ®µ",
		},
		{
			checkColumn: "cache_creation_cost_multiplier",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN cache_creation_cost_multiplier REAL DEFAULT 1.0",
			description: "ç«¯ç‚¹ 5m ç¼“å­˜åˆ›å»ºæˆæœ¬å€ç‡å­—æ®µ",
		},
		{
			checkColumn: "cache_creation_cost_multiplier_1h",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN cache_creation_cost_multiplier_1h REAL DEFAULT 1.0",
			description: "ç«¯ç‚¹ 1h ç¼“å­˜åˆ›å»ºæˆæœ¬å€ç‡å­—æ®µ",
		},
		{
			checkColumn: "cache_read_cost_multiplier",
			alterSQL:    "ALTER TABLE endpoints ADD COLUMN cache_read_cost_multiplier REAL DEFAULT 1.0",
			description: "ç«¯ç‚¹ç¼“å­˜è¯»å–æˆæœ¬å€ç‡å­—æ®µ",
		},
	}

	// channels è¿ç§»ï¼šæ—©æœŸå¯èƒ½åªæœ‰ nameï¼Œåç»­æ–°å¢ website
	channelMigrations := []struct {
		checkColumn string
		alterSQL    string
		description string
	}{
		{
			checkColumn: "website",
			alterSQL:    "ALTER TABLE channels ADD COLUMN website TEXT",
			description: "æ¸ é“å®˜ç½‘å­—æ®µ",
		},
		{
			checkColumn: "priority",
			alterSQL:    "ALTER TABLE channels ADD COLUMN priority INTEGER DEFAULT 1",
			description: "æ¸ é“ä¼˜å…ˆçº§å­—æ®µ",
		},
	}

	runMigrations := func(table string, migrations []struct {
		checkColumn string
		alterSQL    string
		description string
	}) error {
		tableExists, err := s.tableExists(ctx, table)
		if err != nil {
			return fmt.Errorf("failed to check table %s: %w", table, err)
		}
		if !tableExists {
			return nil
		}

		for _, m := range migrations {
			exists, err := s.columnExists(ctx, table, m.checkColumn)
			if err != nil {
				return fmt.Errorf("failed to check column %s.%s: %w", table, m.checkColumn, err)
			}
			if exists {
				continue
			}

			s.logger.Info(fmt.Sprintf("ğŸ”§ [æ•°æ®åº“è¿ç§»] %sï¼šæ·»åŠ  %s", table, m.description))
			if _, err := s.db.ExecContext(ctx, m.alterSQL); err != nil {
				return fmt.Errorf("failed to add column %s.%s: %w", table, m.checkColumn, err)
			}
			s.logger.Info(fmt.Sprintf("âœ… [æ•°æ®åº“è¿ç§»] %sï¼š%s æ·»åŠ æˆåŠŸ", table, m.description))
		}
		return nil
	}

	if err := runMigrations("request_logs", requestLogMigrations); err != nil {
		return err
	}
	if err := runMigrations("endpoints", endpointsMigrations); err != nil {
		return err
	}
	if err := runMigrations("channels", channelMigrations); err != nil {
		return err
	}

	return nil
}

func (s *SQLiteAdapter) tableExists(ctx context.Context, table string) (bool, error) {
	var count int
	if err := s.db.QueryRowContext(ctx, "SELECT COUNT(*) FROM sqlite_master WHERE type='table' AND name = ?", table).Scan(&count); err != nil {
		return false, err
	}
	return count > 0, nil
}

// columnExists æ£€æŸ¥è¡¨ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šåˆ—
func (s *SQLiteAdapter) columnExists(ctx context.Context, table, column string) (bool, error) {
	query := fmt.Sprintf("PRAGMA table_info(%s)", table)
	rows, err := s.db.QueryContext(ctx, query)
	if err != nil {
		return false, err
	}
	defer rows.Close()

	for rows.Next() {
		var cid int
		var name string
		var dataType string
		var notNull int
		var dfltValue interface{}
		var pk int

		if err := rows.Scan(&cid, &name, &dataType, &notNull, &dfltValue, &pk); err != nil {
			return false, err
		}

		if name == column {
			return true, nil
		}
	}

	return false, nil
}

// BuildInsertOrReplaceQuery æ„å»ºæ’å…¥æˆ–æ›´æ–°æŸ¥è¯¢ï¼ˆSQLiteè¯­æ³•ï¼‰
// ä½¿ç”¨ INSERT ... ON CONFLICT DO UPDATE æ¥é¿å…æ•°æ®ä¸¢å¤±
func (s *SQLiteAdapter) BuildInsertOrReplaceQuery(table string, columns []string, values []string) string {
	columnsStr := strings.Join(columns, ", ")
	valuesStr := strings.Join(values, ", ")

	// æ„å»ºINSERTéƒ¨åˆ†
	query := fmt.Sprintf("INSERT INTO %s (%s) VALUES (%s)", table, columnsStr, valuesStr)

	// æ„å»ºON CONFLICT DO UPDATEéƒ¨åˆ†ï¼Œå¯¹start_timeå­—æ®µè¿›è¡Œç‰¹æ®Šå¤„ç†
	// å¯¹äºrequest_logsè¡¨ï¼Œä¸»é”®å†²çªæ—¶æ›´æ–°æä¾›çš„å­—æ®µï¼ˆé™¤äº†request_idä¸»é”®ï¼‰
	var updatePairs []string
	for _, col := range columns {
		if col != "request_id" { // è·³è¿‡ä¸»é”®å­—æ®µ
			if col == "start_time" {
				// å¯¹start_timeä½¿ç”¨COALESCEï¼Œåªåœ¨åŸå€¼ä¸ºNULLæ—¶æ‰æ›´æ–°
				updatePairs = append(updatePairs, fmt.Sprintf("%s = COALESCE(request_logs.%s, EXCLUDED.%s)", col, col, col))
			} else {
				updatePairs = append(updatePairs, fmt.Sprintf("%s = EXCLUDED.%s", col, col))
			}
		}
	}

	if len(updatePairs) > 0 {
		query += " ON CONFLICT(request_id) DO UPDATE SET " + strings.Join(updatePairs, ", ")
	} else {
		// å¦‚æœåªæœ‰request_idå­—æ®µï¼Œåˆ™ä½¿ç”¨IGNOREé¿å…é‡å¤æ’å…¥
		query = fmt.Sprintf("INSERT OR IGNORE INTO %s (%s) VALUES (%s)", table, columnsStr, valuesStr)
	}

	return query
}

// BuildDateTimeNow è¿”å›å½“å‰æ—¶é—´å‡½æ•°ï¼ˆæ”¯æŒå¾®ç§’ç²¾åº¦ï¼‰
// SQLiteæ²¡æœ‰æ—¶åŒºæ”¯æŒï¼Œæˆ‘ä»¬åœ¨Goå±‚é¢ç”Ÿæˆæ­£ç¡®æ—¶åŒºçš„æ—¶é—´å­—ç¬¦ä¸²
func (s *SQLiteAdapter) BuildDateTimeNow() string {
	// è·å–å½“å‰é…ç½®æ—¶åŒºçš„æ—¶é—´
	now := time.Now().In(s.location)

	// æ ¼å¼åŒ–ä¸ºSQLiteå…¼å®¹çš„datetimeæ ¼å¼ï¼ˆå¾®ç§’ç²¾åº¦ï¼‰
	return fmt.Sprintf("'%s'", now.Format("2006-01-02 15:04:05.000000"))
}

// BuildLimitOffset æ„å»ºåˆ†é¡µæŸ¥è¯¢
func (s *SQLiteAdapter) BuildLimitOffset(limit, offset int) string {
	if limit <= 0 {
		return ""
	}
	if offset <= 0 {
		return fmt.Sprintf(" LIMIT %d", limit)
	}
	return fmt.Sprintf(" LIMIT %d OFFSET %d", limit, offset)
}

// VacuumDatabase SQLiteæ‰§è¡ŒVACUUMæ“ä½œ
func (s *SQLiteAdapter) VacuumDatabase(ctx context.Context) error {
	s.logger.Info("æ­£åœ¨æ‰§è¡ŒSQLite VACUUMæ“ä½œ")

	_, err := s.db.ExecContext(ctx, "VACUUM")
	if err != nil {
		return fmt.Errorf("failed to vacuum SQLite database: %w", err)
	}

	s.logger.Info("âœ… SQLite VACUUMæ“ä½œå®Œæˆ")
	return nil
}

// GetDatabaseStats è·å–SQLiteæ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
func (s *SQLiteAdapter) GetDatabaseStats(ctx context.Context) (*DatabaseStats, error) {
	stats := &DatabaseStats{}

	// è·å–è¯·æ±‚è®°å½•æ€»æ•°
	err := s.db.QueryRowContext(ctx, "SELECT COUNT(*) FROM request_logs").Scan(&stats.TotalRequests)
	if err != nil {
		return nil, fmt.Errorf("failed to get total requests count: %w", err)
	}

	// è·å–æ±‡æ€»è®°å½•æ€»æ•°
	err = s.db.QueryRowContext(ctx, "SELECT COUNT(*) FROM usage_summary").Scan(&stats.TotalSummaries)
	if err != nil {
		return nil, fmt.Errorf("failed to get total summaries count: %w", err)
	}

	// è·å–æœ€æ—©å’Œæœ€æ–°çš„è®°å½•æ—¶é—´
	var earliestStr, latestStr sql.NullString
	err = s.db.QueryRowContext(ctx, "SELECT MIN(start_time), MAX(start_time) FROM request_logs").Scan(&earliestStr, &latestStr)
	if err != nil && err != sql.ErrNoRows {
		return nil, fmt.Errorf("failed to get record time range: %w", err)
	}

	if earliestStr.Valid {
		if t, err := time.Parse(time.RFC3339, earliestStr.String); err == nil {
			stats.EarliestRecord = &t
		}
	}
	if latestStr.Valid {
		if t, err := time.Parse(time.RFC3339, latestStr.String); err == nil {
			stats.LatestRecord = &t
		}
	}

	// è·å–æ•°æ®åº“æ–‡ä»¶å¤§å°ï¼ˆSQLiteç‰¹æœ‰ï¼‰
	var pageCount, pageSize int64
	err = s.db.QueryRowContext(ctx, "PRAGMA page_count").Scan(&pageCount)
	if err == nil {
		err = s.db.QueryRowContext(ctx, "PRAGMA page_size").Scan(&pageSize)
		if err == nil {
			stats.DatabaseSize = pageCount * pageSize
		}
	}

	// è·å–æ€»æˆæœ¬
	err = s.db.QueryRowContext(ctx, "SELECT COALESCE(SUM(total_cost_usd), 0) FROM request_logs WHERE total_cost_usd > 0").Scan(&stats.TotalCostUSD)
	if err != nil && err != sql.ErrNoRows {
		return nil, fmt.Errorf("failed to get total cost: %w", err)
	}

	return stats, nil
}

// GetConnectionStats è·å–è¿æ¥æ± ç»Ÿè®¡ä¿¡æ¯
func (s *SQLiteAdapter) GetConnectionStats() ConnectionStats {
	if s.db == nil {
		return ConnectionStats{}
	}

	dbStats := s.db.Stats()
	return ConnectionStats{
		OpenConnections:  dbStats.OpenConnections,
		IdleConnections:  dbStats.Idle,
		InUseConnections: dbStats.InUse,
		WaitCount:        dbStats.WaitCount,
		WaitDuration:     dbStats.WaitDuration,
		MaxLifetime:      0, // SQLiteä¸é™åˆ¶è¿æ¥ç”Ÿå‘½å‘¨æœŸ
	}
}

// GetDatabaseType è¿”å›æ•°æ®åº“ç±»å‹æ ‡è¯†
func (s *SQLiteAdapter) GetDatabaseType() string {
	return "sqlite"
}

// diagnoseTimezoneSettings è¯Šæ–­SQLiteæ—¶åŒºè®¾ç½®ï¼Œå¸®åŠ©è°ƒè¯•æ—¶åŒºä¸ä¸€è‡´é—®é¢˜
func (s *SQLiteAdapter) diagnoseTimezoneSettings() {
	// SQLiteæ—¶åŒºè¯Šæ–­ç›¸å¯¹ç®€å•ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨åº”ç”¨å±‚å¤„ç†æ—¶åŒº
	goNow := time.Now()
	goInConfigTZ := time.Now().In(s.location)

	_, goOffset := goInConfigTZ.Zone()
	goOffsetHours := float64(goOffset) / 3600

	s.logger.Info("ğŸ” SQLiteæ—¶åŒºè¯Šæ–­ä¿¡æ¯",
		"configured_timezone", s.location.String(),
		"system_now", goNow.Format("2006-01-02 15:04:05 -07:00"),
		"configured_tz_now", goInConfigTZ.Format("2006-01-02 15:04:05 -07:00"),
		"configured_offset_hours", goOffsetHours,
		"builddatetimenow_output", s.BuildDateTimeNow())

	// éªŒè¯æ—¶åŒºåç§»æ˜¯å¦ç¬¦åˆé¢„æœŸ
	if s.location.String() == "Asia/Shanghai" && goOffsetHours == 8.0 {
		s.logger.Info("âœ… SQLiteæ—¶åŒºè®¾ç½®æ­£ç¡®: ä½¿ç”¨Asia/Shanghaiæ—¶åŒº (+8å°æ—¶)")
	} else if s.location == time.UTC {
		s.logger.Info("â„¹ï¸  SQLiteä½¿ç”¨UTCæ—¶åŒº")
	} else {
		s.logger.Info("â„¹ï¸  SQLiteä½¿ç”¨è‡ªå®šä¹‰æ—¶åŒº", "timezone", s.location.String(), "offset_hours", goOffsetHours)
	}
}

// getSQLiteAppDataDir è·å–åº”ç”¨æ•°æ®ç›®å½•ï¼ˆè·¨å¹³å°ï¼‰
// å¤åˆ¶è‡ª internal/utils/appdir.goï¼Œé¿å…å¾ªç¯ä¾èµ–
// Windows: %APPDATA%\CC-Forwarder
// macOS: ~/Library/Application Support/CC-Forwarder
// Linux: ~/.local/share/cc-forwarder
func getSQLiteAppDataDir() string {
	var baseDir string

	switch runtime.GOOS {
	case "windows":
		baseDir = os.Getenv("APPDATA")
		if baseDir == "" {
			baseDir = filepath.Join(os.Getenv("USERPROFILE"), "AppData", "Roaming")
		}
		return filepath.Join(baseDir, "CC-Forwarder")

	case "darwin":
		homeDir, _ := os.UserHomeDir()
		return filepath.Join(homeDir, "Library", "Application Support", "CC-Forwarder")

	case "linux":
		homeDir, _ := os.UserHomeDir()
		xdgDataHome := os.Getenv("XDG_DATA_HOME")
		if xdgDataHome != "" {
			return filepath.Join(xdgDataHome, "cc-forwarder")
		}
		return filepath.Join(homeDir, ".local", "share", "cc-forwarder")

	default:
		homeDir, _ := os.UserHomeDir()
		return filepath.Join(homeDir, ".cc-forwarder")
	}
}
